{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import openai\n",
    "from PyPDF2 import PdfReader\n",
    "sys.path.append(sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(\"utils\")))))\n",
    "from utils import TomideBeautifulSoupUtils, google_search, TomsEmailUtilities\n",
    "openai.api_key = \"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\"\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mad_memo(company_name, company_website, pitch_deck):\n",
    "    directory = './decks/africa/'\n",
    "\n",
    "    pitch_deck = 'Pivo Pitch Deck - Main (1).pdf'\n",
    "\n",
    "    files = os.listdir(directory) \n",
    "\n",
    "    reader = PdfReader(f'{directory}/{pitch_deck}')\n",
    "\n",
    "    pitch_deck_content = ''.join([ page.extract_text().strip() for page in reader.pages ])\n",
    "\n",
    "    website_content = TomideBeautifulSoupUtils.tomide_bs4_make_soup(company_website, 'incognitp', False)\n",
    "\n",
    "    dataset = pitch_deck_content + website_content[0].text.strip()\n",
    "\n",
    "    print(f'Deck: {len(pitch_deck_content)} | Website: {len(website_content[0].text.strip())} | Dataset: {len(dataset)}')\n",
    "\n",
    "    dataset = ''.join([ dataset.replace(thing, '') for thing in ['\\n', 'all rights reserved', '©', '®', '™', ] ])\n",
    "\n",
    "    emails = re.findall(r'[\\w\\.-]+@[\\w\\.-]+', dataset)\n",
    "\n",
    "    founder_google_search = ''.join(founder['snippet'] + ' ' + founder['htmlSnippet'] for founder in google_search(f'{company_name} startup founders'))\n",
    "    founder_google_search = founder_google_search.strip().replace('<b>', '').replace('</b>', '')    \n",
    "\n",
    "    funding_raise_google_search =  ''.join(funding['snippet'] + ' ' + funding['htmlSnippet'] for funding in google_search(f'{company_name} funding raise'))\n",
    "    funding_raise_google_search = funding_raise_google_search.strip().replace('</b>', '').replace('<b>', '')\n",
    "\n",
    "    class Prompts:\n",
    "        what_they_do = \"extract what the company does from the data here \"\n",
    "        \n",
    "        hundred_x_justification = \"based on the available data how can the company make 100x return? What will it have to be valued at to make that return? Is the market large enough to allow the company to grow to a 100x? And does the company and the team have what it takes to attain that feat?\"\n",
    "        traction = \"extract traction from the data here Is the product at MVP or further. How far along in development are they?\"\n",
    "        \n",
    "        team = \"extract founders names and details from the data here\"\n",
    "        founder_vision = \"extract founder's vision from the data here What is the founder’s vision for the company or market and why? What are the founder's motivation and what drives them?\"\n",
    "        \n",
    "        business_model = \"extract business model from the data here How does the company make its money?\"\n",
    "        funding = \"extract funding from the data here\"\n",
    "        use_of_funds = \"extract use of funds from the data here What does the team plan to use this raise for? \"\n",
    "        \n",
    "        industry = \"extract industry from the data here What industry is the company in?\"\n",
    "        market = \"extract market from the data here General Market outlook What is the size of the market? How has it grown over time? What portion of the market has the company decided that they can service?\"\n",
    "        risks = 'What are the risks that come with this company? A risk in their product, service, or business model? What could make it fail? What do they need to get absolutely perfect to ensure they succeed?'\n",
    "\n",
    "        products = \"extract the company's product from the data here What is the Product/Service they are providing?\"\n",
    "        revenue = \"extract revenue from the data here\"\n",
    "        growth = \"extract growth from the data here\"\n",
    "        competition = \"extract competition from the data here\"\n",
    "        exit_opp = \"extract exit from the data here\"\n",
    "        \n",
    "        contact = \"extract contact phone and emailfrom the data here\"\n",
    "        website = \"extract website from the data here\"\n",
    "        location = \"extract the company's location from the data here\"\n",
    "\n",
    "    class QueryGpt:\n",
    "        def __init__(self, query, dataset):\n",
    "            self.query = query\n",
    "            self.dataset = dataset\n",
    "\n",
    "        def query_gpt(self):\n",
    "            response = openai.Completion.create(\n",
    "            engine=\"text-davinci-003\",\n",
    "            prompt= self.query+ '' + self.dataset,\n",
    "            temperature=0.7,\n",
    "            max_tokens=2009,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0)\n",
    "            print(response.choices[0].text.strip())\n",
    "            return response.choices[0].text.strip()\n",
    "\n",
    "\n",
    "    class MemoCreator:\n",
    "        def memoCreate():\n",
    "            \n",
    "            memo = f'''\n",
    "    <==========INVESTMENT MEMO============>\n",
    "    # generate a word document with this content\n",
    "\n",
    "    WHAT THEY DO: \n",
    "    {QueryGpt(Prompts.what_they_do, dataset).query_gpt()}\n",
    "\n",
    "    QueryGpt(Prompts.hundred_x_justification, dataset).query_gpt()\n",
    "\n",
    "    DECK | WEBSITE \n",
    "    # store in db and generate link\n",
    "    {company_website if company_website else QueryGpt(Prompts.website, dataset).query_gpt()} | link to pictchdeck\n",
    "\n",
    "    ROUND DETAILS\n",
    "    Terms: How much are we investing and what valuation?\n",
    "    Stage: Pre-Seed/Seed/Series ABC?\n",
    "    Co-Investors: If any?\n",
    "    Information Rights: \n",
    "    Pro-Rata:\n",
    "    City: {QueryGpt(Prompts.location, dataset).query_gpt()}\n",
    "    Sex:\n",
    "    Industry: {QueryGpt(Prompts.industry, dataset).query_gpt()}\n",
    "\n",
    "    TRACTION AND PROGRESS SO FAR:\n",
    "    {QueryGpt(Prompts.traction, dataset).query_gpt()}\n",
    "\n",
    "    Founders: Founder Info from Linkedin and Execution Ability\n",
    "    Are they repeat founders? Do they have other things going on? Do they have what it takes to achieve their vision?\n",
    "    # pull data from Linkedin previously listed companies \n",
    "    {QueryGpt(Prompts.team, founder_google_search).query_gpt()}\n",
    "\n",
    "    BUSINESS MODEL\n",
    "    {QueryGpt(Prompts.business_model, dataset).query_gpt()}\n",
    "\n",
    "    FOUNDER'S VISION\n",
    "    {QueryGpt(Prompts.founder_vision, founder_google_search).query_gpt()}\n",
    "\n",
    "    FUNDING:\n",
    "    {QueryGpt(Prompts.funding, funding_raise_google_search).query_gpt()}\n",
    "\n",
    "    USE OF FUNDS:\n",
    "    {QueryGpt(Prompts.use_of_funds, dataset).query_gpt()}\n",
    "\n",
    "    PRODUCT/SERVICE:\n",
    "    {QueryGpt(Prompts.products, dataset).query_gpt()}\n",
    "\n",
    "    CONTACTS: :\n",
    "    {QueryGpt(Prompts.contact, dataset).query_gpt()}\n",
    "    emails: {' | '.join(emails)}\n",
    "\n",
    "    MARKET OUTLOOK\n",
    "    {QueryGpt(Prompts.market, dataset).query_gpt()}\n",
    "\n",
    "    COMPETITION & DEFENSIBILITY\n",
    "    Who is their competition? How do they compare against each other? What is unique about this company that makes them stand out in the market? Feel free to use a table here to help compare\n",
    "    # go online to fetch the data here and use exiting companies in the database\n",
    "\n",
    "    RISKS\n",
    "    {QueryGpt(Prompts.risks, dataset).query_gpt()}\n",
    "\n",
    "    Socials:\n",
    "    {' | '.join(website_content[1]['social_media_links'])}\n",
    "\n",
    "    Other Link:\n",
    "    {' | '.join(website_content[1]['internal_links'])}\n",
    "\n",
    "    '''\n",
    "\n",
    "            return memo\n",
    "\n",
    "    print(MemoCreator.memoCreate())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deck: 7286 | Website: 3116 | Dataset: 10402\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens, however you requested 14749 tokens (12740 in your prompt; 2009 for the completion). Please reduce your prompt; or completion length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m generate_mad_memo(\u001b[39m'\u001b[39m\u001b[39mPivo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhttps://pivo.africa/\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn [5], line 150\u001b[0m, in \u001b[0;36mgenerate_mad_memo\u001b[0;34m(company_name, company_website, pitch_deck)\u001b[0m\n\u001b[1;32m     80\u001b[0m         memo \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'''\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[39m<==========INVESTMENT MEMO============>\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[39m# generate a word document with this content\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[39mreturn\u001b[39;00m memo\n\u001b[0;32m--> 150\u001b[0m \u001b[39mprint\u001b[39m(MemoCreator\u001b[39m.\u001b[39;49mmemoCreate())\n",
      "Cell \u001b[0;32mIn [5], line 85\u001b[0m, in \u001b[0;36mgenerate_mad_memo.<locals>.MemoCreator.memoCreate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mmemoCreate\u001b[39m():\n\u001b[1;32m     80\u001b[0m         memo \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'''\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[39m<==========INVESTMENT MEMO============>\u001b[39m\n\u001b[1;32m     82\u001b[0m \u001b[39m# generate a word document with this content\u001b[39m\n\u001b[1;32m     83\u001b[0m \n\u001b[1;32m     84\u001b[0m \u001b[39mWHAT THEY DO: \u001b[39m\n\u001b[0;32m---> 85\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mwhat_they_do, dataset)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m     86\u001b[0m \n\u001b[1;32m     87\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mhundred_x_justification, dataset)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \n\u001b[1;32m     89\u001b[0m \u001b[39mDECK | WEBSITE \u001b[39m\n\u001b[1;32m     90\u001b[0m \u001b[39m# store in db and generate link\u001b[39m\n\u001b[1;32m     91\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mcompany_website\u001b[39m}\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \n\u001b[1;32m     93\u001b[0m \u001b[39mROUND DETAILS\u001b[39m\n\u001b[1;32m     94\u001b[0m \u001b[39mTerms: How much are we investing and what valuation?\u001b[39m\n\u001b[1;32m     95\u001b[0m \u001b[39mStage: Pre-Seed/Seed/Series ABC?\u001b[39m\n\u001b[1;32m     96\u001b[0m \u001b[39mCo-Investors: If any?\u001b[39m\n\u001b[1;32m     97\u001b[0m \u001b[39mInformation Rights: \u001b[39m\n\u001b[1;32m     98\u001b[0m \u001b[39mPro-Rata:\u001b[39m\n\u001b[1;32m     99\u001b[0m \u001b[39mCity: \u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mlocation, dataset)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[39mSex:\u001b[39m\n\u001b[1;32m    101\u001b[0m \u001b[39mIndustry: \u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mindustry, dataset)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m \u001b[39mTRACTION AND PROGRESS SO FAR:\u001b[39m\n\u001b[1;32m    104\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mtraction, dataset)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[39mFounders: Founder Info from Linkedin and Execution Ability\u001b[39m\n\u001b[1;32m    107\u001b[0m \u001b[39mAre they repeat founders? Do they have other things going on? Do they have what it takes to achieve their vision?\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[39m# pull data from Linkedin previously listed companies \u001b[39m\n\u001b[1;32m    109\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mteam, founder_google_search)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    110\u001b[0m \n\u001b[1;32m    111\u001b[0m \u001b[39mBUSINESS MODEL\u001b[39m\n\u001b[1;32m    112\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mbusiness_model, dataset)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \n\u001b[1;32m    114\u001b[0m \u001b[39mFOUNDER\u001b[39m\u001b[39m'\u001b[39m\u001b[39mS VISION\u001b[39m\n\u001b[1;32m    115\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mfounder_vision, founder_google_search)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \n\u001b[1;32m    117\u001b[0m \u001b[39mFUNDING:\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mfunding, funding_raise_google_search)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \n\u001b[1;32m    120\u001b[0m \u001b[39mUSE OF FUNDS:\u001b[39m\n\u001b[1;32m    121\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39muse_of_funds, dataset)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \n\u001b[1;32m    123\u001b[0m \u001b[39mPRODUCT/SERVICE:\u001b[39m\n\u001b[1;32m    124\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mproducts, dataset)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \n\u001b[1;32m    126\u001b[0m \u001b[39mCONTACTS: :\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mcontact, dataset)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[39memails: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m | \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(emails)\u001b[39m}\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \n\u001b[1;32m    130\u001b[0m \u001b[39mMARKET OUTLOOK\u001b[39m\n\u001b[1;32m    131\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mmarket, dataset)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \n\u001b[1;32m    133\u001b[0m \u001b[39mCOMPETITION & DEFENSIBILITY\u001b[39m\n\u001b[1;32m    134\u001b[0m \u001b[39mWho is their competition? How do they compare against each other? What is unique about this company that makes them stand out in the market? Feel free to use a table here to help compare\u001b[39m\n\u001b[1;32m    135\u001b[0m \u001b[39m# go online to fetch the data here and use exiting companies in the database\u001b[39m\n\u001b[1;32m    136\u001b[0m \n\u001b[1;32m    137\u001b[0m \u001b[39mRISKS\u001b[39m\n\u001b[1;32m    138\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00mQueryGpt(Prompts\u001b[39m.\u001b[39mrisks, dataset)\u001b[39m.\u001b[39mquery_gpt()\u001b[39m}\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \n\u001b[1;32m    140\u001b[0m \u001b[39mSocials:\u001b[39m\n\u001b[1;32m    141\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m | \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(website_content[\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msocial_media_links\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m}\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \n\u001b[1;32m    143\u001b[0m \u001b[39mOther Link:\u001b[39m\n\u001b[1;32m    144\u001b[0m \u001b[39m\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m | \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(website_content[\u001b[39m1\u001b[39m][\u001b[39m'\u001b[39m\u001b[39minternal_links\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m}\u001b[39;00m\n\u001b[1;32m    145\u001b[0m \n\u001b[1;32m    146\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[39mreturn\u001b[39;00m memo\n",
      "Cell \u001b[0;32mIn [5], line 66\u001b[0m, in \u001b[0;36mgenerate_mad_memo.<locals>.QueryGpt.query_gpt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery_gpt\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m---> 66\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[1;32m     67\u001b[0m     engine\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtext-davinci-003\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     68\u001b[0m     prompt\u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mquery\u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39m+\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset,\n\u001b[1;32m     69\u001b[0m     temperature\u001b[39m=\u001b[39;49m\u001b[39m0.7\u001b[39;49m,\n\u001b[1;32m     70\u001b[0m     max_tokens\u001b[39m=\u001b[39;49m\u001b[39m2009\u001b[39;49m,\n\u001b[1;32m     71\u001b[0m     top_p\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     72\u001b[0m     frequency_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     73\u001b[0m     presence_penalty\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     74\u001b[0m     \u001b[39mprint\u001b[39m(response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip())\n\u001b[1;32m     75\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\u001b[39m.\u001b[39mstrip()\n",
      "File \u001b[0;32m~/Documents/GitHub/TomsWebScrapingCargo/venv/lib/python3.9/site-packages/openai/api_resources/completion.py:25\u001b[0m, in \u001b[0;36mCompletion.create\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[0;32m~/Documents/GitHub/TomsWebScrapingCargo/venv/lib/python3.9/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[1;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[1;32m    137\u001b[0m ):\n\u001b[1;32m    138\u001b[0m     (\n\u001b[1;32m    139\u001b[0m         deployment_id,\n\u001b[1;32m    140\u001b[0m         engine,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[1;32m    151\u001b[0m     )\n\u001b[0;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[1;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    155\u001b[0m         url,\n\u001b[1;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[1;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[1;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[1;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[1;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[0;32m~/Documents/GitHub/TomsWebScrapingCargo/venv/lib/python3.9/site-packages/openai/api_requestor.py:226\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[1;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    207\u001b[0m     method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m    216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[1;32m    217\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[1;32m    218\u001b[0m         url,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[1;32m    225\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[1;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[0;32m~/Documents/GitHub/TomsWebScrapingCargo/venv/lib/python3.9/site-packages/openai/api_requestor.py:619\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[0;34m(self, result, stream)\u001b[0m\n\u001b[1;32m    611\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    612\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[1;32m    613\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    614\u001b[0m         )\n\u001b[1;32m    615\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[1;32m    616\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    618\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 619\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[1;32m    620\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    621\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[1;32m    622\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    623\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    624\u001b[0m         ),\n\u001b[1;32m    625\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    626\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/GitHub/TomsWebScrapingCargo/venv/lib/python3.9/site-packages/openai/api_requestor.py:679\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[0;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[1;32m    677\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[1;32m    678\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[0;32m--> 679\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[1;32m    680\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[1;32m    681\u001b[0m     )\n\u001b[1;32m    682\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[0;31mInvalidRequestError\u001b[0m: This model's maximum context length is 4097 tokens, however you requested 14749 tokens (12740 in your prompt; 2009 for the completion). Please reduce your prompt; or completion length."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens=4097\n",
    "tokens_in_number = 4097 * 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "fdc41f0eadf12055021ad23f87a8a9ee8e96f5c00b057f56ee298e5db47363e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
